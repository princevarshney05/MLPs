This project delves into implementing Multilayer Perceptrons (MLPs) using PyTorch for accurate digit prediction utilizing the MNIST dataset. It encompasses a comprehensive exploration of optimization techniques, including various optimizers and schedulers, while also incorporating advanced strategies like batch normalization and dropout to enhance model performance. The study also encompasses diverse batching techniques, contributing to a deeper understanding of their impact on model training and effectiveness. This undertaking offers a holistic perspective on contemporary neural network methodologies, combining theoretical insights with practical implementation expertise.